{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c63237ddf8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "preprocess = data_transforms['test'] = data_transforms['val']\n",
    "\n",
    "preprocess = data_transforms['val']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gafed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\PIL\\Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "copy_from = os.path.join(os.getcwd(), 'photoset_5000')\n",
    "path_to_download = os.path.join(os.getcwd(), 'data', 'photos_5000_v_7.csv')\n",
    "\n",
    "df = pd.read_csv(path_to_download)\n",
    "\n",
    "res = []\n",
    "for i, row in df.iterrows():\n",
    "    photo_path = os.path.join(copy_from, 'photo{0}.jpg'.format(i))\n",
    "    \n",
    "    #try:\n",
    "    if os.path.exists(photo_path):\n",
    "        input_image = Image.open(photo_path).convert('RGB')\n",
    "\n",
    "        input_tensor = preprocess(input_image)\n",
    "        input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_batch).squeeze()\n",
    "        res.append(output.numpy())\n",
    "    else:\n",
    "        res.append(np.array([None]*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_df = pd.DataFrame(data=np.stack(res).astype(np.float), columns=[f'resnet_{i}' for i in range(512)])\n",
    "data = np.concatenate([df[['Amount of subscribers', 'Amount of likes']].values, np.stack(res).astype(np.float)], axis=1)\n",
    "_data = data[data[:, -1] == data[:, -1]] # dummy filtering\n",
    "np.save(os.path.join(os.getcwd(), 'data', 'photos_5000_v_8_resnet__subscribers_likes_resnet.npy'), _data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = np.load(os.path.join(os.getcwd(), 'data', 'photos_5000_v_8_resnet__subscribers_likes_resnet.npy'))\n",
    "\n",
    "_data_trainval, _data_test = train_test_split(_data, test_size=0.1)\n",
    "\n",
    "\n",
    "_data_train, _data_val = train_test_split(_data_trainval, test_size=0.1)\n",
    "\n",
    "np.save(os.path.join(os.getcwd(), 'data', 'photos_4500(3859)_v_8_resnet__subscribers_likes_resnet_train.npy'), _data_train)\n",
    "np.save(os.path.join(os.getcwd(), 'data', 'photos_4500(3859)_v_8_resnet__subscribers_likes_resnet_val.npy'), _data_val)\n",
    "np.save(os.path.join(os.getcwd(), 'data', 'photos_4500(3859)_v_8_resnet__subscribers_likes_resnet_test.npy'), _data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = {}\n",
    "_data['train'] = np.load(os.path.join(os.getcwd(), 'data', 'photos_5000_v_8_resnet__subscribers_likes_resnet_train.npy'))\n",
    "_data['val'] = np.load(os.path.join(os.getcwd(), 'data', 'photos_5000_v_8_resnet__subscribers_likes_resnet_val.npy'))\n",
    "_data['test'] = np.load(os.path.join(os.getcwd(), 'data', 'photos_5000_v_8_resnet__subscribers_likes_resnet_test.npy'), )\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(_data_train[:, :1])\n",
    "\n",
    "def get_dataset(_data, scaler):\n",
    "    _data[:, 1] /= _data[:, 0] + 1e-9\n",
    "    _data[:, :1] = scaler.transform(_data[:, :1])\n",
    "    _data = torch.tensor(_data).float()\n",
    "    _dataset = torch.utils.data.TensorDataset(_data)\n",
    "    return _dataset\n",
    "\n",
    "dataloaders = {}\n",
    "for key in _data:\n",
    "    dataloaders[key] = torch.utils.data.DataLoader(get_dataset(_data[key], scaler), batch_size=5, shuffle=True)\n",
    "    \n",
    "    \n",
    "# _data_train[:, :1] = scaler.transform(_data_train[:, :1])\n",
    "# _data_test[:, :1] = scaler.transform(_data_test[:, :1])\n",
    "\n",
    "\n",
    "# _data_train = torch.tensor(_data_train).float()\n",
    "# train_dataset = torch.utils.data.TensorDataset(_data_train)\n",
    "\n",
    "# # scaler = preprocessing.StandardScaler().fit(train_dataset[:, :2])\n",
    "\n",
    "# _data_test = torch.tensor(_data_test).float()\n",
    "# test_dataset = torch.utils.data.TensorDataset(_data_test)\n",
    "\n",
    "\n",
    "# dataloaders = {\n",
    "#     'train': torch.utils.data.DataLoader(train_dataset, batch_size=5),\n",
    "#     'val': torch.utils.data.DataLoader(test_dataset, batch_size=5),\n",
    "# }\n",
    "\n",
    "class BaselineNet(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(512, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size + 1, hidden_size + 1 // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size + 1 // 2, 1)\n",
    "        \n",
    "    def forward(self, resnet_features, user_features):\n",
    "        # resnet_features B x 512\n",
    "        # user_features B x 1\n",
    "        x = self.fc1(resnet_features) # B x 20\n",
    "        x = torch.cat([x, user_features], dim=1) # B x 21\n",
    "        x = nn.functional.relu(x) # B x 21\n",
    "        x = self.fc2(x) # B x 10\n",
    "        x = nn.functional.relu(x) # B x 10\n",
    "        x = self.fc3(x) # B x 1\n",
    "        return x\n",
    "\n",
    "if False:\n",
    "    net = BaselineNet(20)\n",
    "    batch = next(iter(dataloaders['train']))\n",
    "    user_features, gt, resnet_features = batch[0][:, :1], batch[0][:, 1:2], batch[0][:, 2:]\n",
    "    res = net(resnet_features, user_features)\n",
    "    print(res)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs=25, phases=('train', 'val', 'test')):\n",
    "    since = time.time()\n",
    "    \n",
    "    history = defaultdict(list)\n",
    "    \n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in phases:\n",
    "            \n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()  \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_custom_metric = .0\n",
    "            phase_len = 0\n",
    "\n",
    "            for batch in dataloaders[phase]:\n",
    "                \n",
    "                user_features, gt, resnet_features = batch[0][:, :1], batch[0][:, 1:2], batch[0][:, 2:]\n",
    "#                 print(user_features, gt)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(resnet_features, user_features)\n",
    "                    loss = criterion(outputs, gt)\n",
    "                    custom_metric = (torch.abs(1 - outputs.squeeze() / (gt + 0.000001).squeeze())).sum()\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * user_features.size(0)\n",
    "                running_custom_metric += custom_metric.item()\n",
    "                phase_len += user_features.size(0)\n",
    "                history[f'{phase}_running_loss'].append(loss.item() * user_features.size(0))\n",
    "                history[f'{phase}_running_custom_metric'].append(custom_metric.item())\n",
    "#                 print(running_loss, phase_len)\n",
    "                \n",
    "                \n",
    "                \n",
    "            history[f'{phase}_mean_epoch_loss'].append(running_loss / phase_len)\n",
    "            history[f'{phase}_mean_epoch_custom_metric'].append(running_custom_metric / phase_len)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss\n",
    "\n",
    "            print('{} Loss: {:.4f} Custom metric: {:.4f}'.format(\n",
    "                phase, epoch_loss / phase_len, running_custom_metric / phase_len))\n",
    "\n",
    "            if phase == 'val' and running_custom_metric / phase_len < best_acc:\n",
    "                best_acc = running_custom_metric / phase_len\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print(epoch, 'best weights update')\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "#     print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "#         time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model, history, best_model_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/34\n",
      "----------\n",
      "train Loss: 0.0202 Custom metric: 8.0774\n",
      "val Loss: 0.0224 Custom metric: 15.4560\n",
      "0 best weights update\n",
      "test Loss: 0.0183 Custom metric: 11.0009\n",
      "\n",
      "Epoch 1/34\n",
      "----------\n",
      "train Loss: 0.0183 Custom metric: 6.8573\n",
      "val Loss: 0.0225 Custom metric: 5.5819\n",
      "1 best weights update\n",
      "test Loss: 0.0156 Custom metric: 4.7599\n",
      "\n",
      "Epoch 2/34\n",
      "----------\n",
      "train Loss: 0.0173 Custom metric: 6.2954\n",
      "val Loss: 0.0218 Custom metric: 6.9971\n",
      "test Loss: 0.0149 Custom metric: 5.3392\n",
      "\n",
      "Epoch 3/34\n",
      "----------\n",
      "train Loss: 0.0169 Custom metric: 6.7529\n",
      "val Loss: 0.0216 Custom metric: 8.5764\n",
      "test Loss: 0.0150 Custom metric: 5.9650\n",
      "\n",
      "Epoch 4/34\n",
      "----------\n",
      "train Loss: 0.0167 Custom metric: 6.0934\n",
      "val Loss: 0.0218 Custom metric: 6.5482\n",
      "test Loss: 0.0150 Custom metric: 5.1215\n",
      "\n",
      "Epoch 5/34\n",
      "----------\n",
      "train Loss: 0.0168 Custom metric: 6.0157\n",
      "val Loss: 0.0218 Custom metric: 5.1658\n",
      "5 best weights update\n",
      "test Loss: 0.0149 Custom metric: 4.7465\n",
      "\n",
      "Epoch 6/34\n",
      "----------\n",
      "train Loss: 0.0167 Custom metric: 5.6219\n",
      "val Loss: 0.0216 Custom metric: 6.9309\n",
      "test Loss: 0.0150 Custom metric: 6.3167\n",
      "\n",
      "Epoch 7/34\n",
      "----------\n",
      "train Loss: 0.0168 Custom metric: 5.9798\n",
      "val Loss: 0.0215 Custom metric: 8.4967\n",
      "test Loss: 0.0147 Custom metric: 5.4268\n",
      "\n",
      "Epoch 8/34\n",
      "----------\n",
      "train Loss: 0.0166 Custom metric: 5.5065\n",
      "val Loss: 0.0215 Custom metric: 5.2118\n",
      "test Loss: 0.0146 Custom metric: 4.6548\n",
      "\n",
      "Epoch 9/34\n",
      "----------\n",
      "train Loss: 0.0166 Custom metric: 5.1063\n",
      "val Loss: 0.0225 Custom metric: 12.1359\n",
      "test Loss: 0.0160 Custom metric: 5.7979\n",
      "\n",
      "Epoch 10/34\n",
      "----------\n",
      "train Loss: 0.0166 Custom metric: 5.4725\n",
      "val Loss: 0.0214 Custom metric: 6.5122\n",
      "test Loss: 0.0146 Custom metric: 5.0825\n",
      "\n",
      "Epoch 11/34\n",
      "----------\n",
      "train Loss: 0.0166 Custom metric: 4.9721\n",
      "val Loss: 0.0214 Custom metric: 5.4867\n",
      "test Loss: 0.0145 Custom metric: 4.6836\n",
      "\n",
      "Epoch 12/34\n",
      "----------\n",
      "train Loss: 0.0166 Custom metric: 5.1689\n",
      "val Loss: 0.0216 Custom metric: 4.3114\n",
      "12 best weights update\n",
      "test Loss: 0.0146 Custom metric: 3.6341\n",
      "\n",
      "Epoch 13/34\n",
      "----------\n",
      "train Loss: 0.0165 Custom metric: 4.6899\n",
      "val Loss: 0.0214 Custom metric: 5.8561\n",
      "test Loss: 0.0145 Custom metric: 4.2965\n",
      "\n",
      "Epoch 14/34\n",
      "----------\n",
      "train Loss: 0.0165 Custom metric: 4.7990\n",
      "val Loss: 0.0214 Custom metric: 4.9782\n",
      "test Loss: 0.0145 Custom metric: 3.8559\n",
      "\n",
      "Epoch 15/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.4866\n",
      "val Loss: 0.0214 Custom metric: 5.4865\n",
      "test Loss: 0.0144 Custom metric: 4.0374\n",
      "\n",
      "Epoch 16/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.6346\n",
      "val Loss: 0.0214 Custom metric: 5.8950\n",
      "test Loss: 0.0144 Custom metric: 4.1441\n",
      "\n",
      "Epoch 17/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.6428\n",
      "val Loss: 0.0214 Custom metric: 6.3256\n",
      "test Loss: 0.0144 Custom metric: 4.3032\n",
      "\n",
      "Epoch 18/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.6626\n",
      "val Loss: 0.0214 Custom metric: 5.6249\n",
      "test Loss: 0.0144 Custom metric: 4.0398\n",
      "\n",
      "Epoch 19/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.6465\n",
      "val Loss: 0.0214 Custom metric: 5.6474\n",
      "test Loss: 0.0144 Custom metric: 4.1556\n",
      "\n",
      "Epoch 20/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.5862\n",
      "val Loss: 0.0214 Custom metric: 5.7841\n",
      "test Loss: 0.0144 Custom metric: 4.2528\n",
      "\n",
      "Epoch 21/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.7263\n",
      "val Loss: 0.0214 Custom metric: 6.2674\n",
      "test Loss: 0.0144 Custom metric: 4.2681\n",
      "\n",
      "Epoch 22/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.6591\n",
      "val Loss: 0.0214 Custom metric: 4.7129\n",
      "test Loss: 0.0144 Custom metric: 4.0819\n",
      "\n",
      "Epoch 23/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.5543\n",
      "val Loss: 0.0214 Custom metric: 6.1521\n",
      "test Loss: 0.0144 Custom metric: 4.2249\n",
      "\n",
      "Epoch 24/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.7224\n",
      "val Loss: 0.0214 Custom metric: 5.0261\n",
      "test Loss: 0.0145 Custom metric: 3.7816\n",
      "\n",
      "Epoch 25/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.4781\n",
      "val Loss: 0.0214 Custom metric: 6.0528\n",
      "test Loss: 0.0144 Custom metric: 4.1287\n",
      "\n",
      "Epoch 26/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.4756\n",
      "val Loss: 0.0214 Custom metric: 6.8970\n",
      "test Loss: 0.0144 Custom metric: 4.4476\n",
      "\n",
      "Epoch 27/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.7004\n",
      "val Loss: 0.0214 Custom metric: 5.3563\n",
      "test Loss: 0.0144 Custom metric: 3.9622\n",
      "\n",
      "Epoch 28/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.5625\n",
      "val Loss: 0.0214 Custom metric: 5.7274\n",
      "test Loss: 0.0144 Custom metric: 4.0807\n",
      "\n",
      "Epoch 29/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.6907\n",
      "val Loss: 0.0214 Custom metric: 5.6688\n",
      "test Loss: 0.0144 Custom metric: 3.9746\n",
      "\n",
      "Epoch 30/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.4837\n",
      "val Loss: 0.0214 Custom metric: 5.7578\n",
      "test Loss: 0.0144 Custom metric: 4.0148\n",
      "\n",
      "Epoch 31/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.5202\n",
      "val Loss: 0.0214 Custom metric: 5.7525\n",
      "test Loss: 0.0144 Custom metric: 4.0179\n",
      "\n",
      "Epoch 32/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.5508\n",
      "val Loss: 0.0214 Custom metric: 5.7777\n",
      "test Loss: 0.0144 Custom metric: 4.0309\n",
      "\n",
      "Epoch 33/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.5545\n",
      "val Loss: 0.0214 Custom metric: 5.7534\n",
      "test Loss: 0.0144 Custom metric: 4.0224\n",
      "\n",
      "Epoch 34/34\n",
      "----------\n",
      "train Loss: 0.0164 Custom metric: 4.5806\n",
      "val Loss: 0.0214 Custom metric: 5.7275\n",
      "test Loss: 0.0144 Custom metric: 4.0153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = BaselineNet(20)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.6)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size = 15, gamma = 0.1)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "model, history, best_model_wts = train_model(\n",
    "    net,\n",
    "    loss,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    dataloaders,\n",
    "    35\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "test Loss: 0.0191 Custom metric: 5.2628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, history, _ = train_model(\n",
    "    net,\n",
    "    loss,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    dataloaders,\n",
    "    1,\n",
    "    ['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'test_running_loss': [0.010889249388128519,\n",
       "              0.7070839405059814,\n",
       "              0.02346085850149393,\n",
       "              0.018584707286208868,\n",
       "              0.030637443996965885,\n",
       "              0.07420681416988373,\n",
       "              0.033581145107746124,\n",
       "              0.1319679617881775,\n",
       "              0.04360106308013201,\n",
       "              0.3098607435822487,\n",
       "              0.013271580683067441,\n",
       "              0.015325143467634916,\n",
       "              0.2378075197339058,\n",
       "              0.02705950988456607,\n",
       "              0.031825932674109936,\n",
       "              0.41823845356702805,\n",
       "              0.0313556264154613,\n",
       "              0.017331389244645834,\n",
       "              0.04016744904220104,\n",
       "              0.027836484368890524,\n",
       "              0.024484568275511265,\n",
       "              0.012114692945033312,\n",
       "              0.01261169440113008,\n",
       "              0.1917264424264431,\n",
       "              0.03262782469391823,\n",
       "              0.06910908035933971,\n",
       "              0.03156181890517473,\n",
       "              0.020748896058648825,\n",
       "              0.056646568700671196,\n",
       "              0.021444542799144983,\n",
       "              0.033979122526943684,\n",
       "              0.02667653141543269,\n",
       "              0.40132269263267517,\n",
       "              0.015147521626204252,\n",
       "              0.03880685195326805,\n",
       "              0.010490387212485075,\n",
       "              0.05206908565014601,\n",
       "              0.028047531377524137,\n",
       "              0.5569013953208923,\n",
       "              0.4373423010110855,\n",
       "              0.04872271325439215,\n",
       "              0.40379710495471954,\n",
       "              0.019987986888736486,\n",
       "              0.15704810619354248,\n",
       "              0.025804881006479263,\n",
       "              0.01351086306385696,\n",
       "              0.029084538109600544,\n",
       "              0.14670653268694878,\n",
       "              0.01428320654667914,\n",
       "              0.01867863116785884,\n",
       "              0.00682131212670356,\n",
       "              0.04920340143144131,\n",
       "              0.014500898541882634,\n",
       "              0.1529838889837265,\n",
       "              0.024336345959454775,\n",
       "              0.01067103585228324,\n",
       "              0.5870957300066948,\n",
       "              0.059929327107965946,\n",
       "              0.05140474531799555,\n",
       "              0.08941470645368099,\n",
       "              0.02169431420043111,\n",
       "              0.09658925235271454,\n",
       "              0.010905953822657466,\n",
       "              0.025413527619093657,\n",
       "              0.30303236097097397,\n",
       "              0.08242138661444187,\n",
       "              0.014093411155045033,\n",
       "              0.09272593073546886,\n",
       "              0.04101634956896305,\n",
       "              0.028712523635476828,\n",
       "              0.10274824686348438,\n",
       "              0.048822248354554176,\n",
       "              0.0443227868527174,\n",
       "              0.06291159894317389,\n",
       "              0.013529618736356497,\n",
       "              0.03400235902518034,\n",
       "              0.10145078413188457,\n",
       "              0.007260995917022228],\n",
       "             'test_running_custom_metric': [5.22235107421875,\n",
       "              8.238173484802246,\n",
       "              7.844704627990723,\n",
       "              24.76456069946289,\n",
       "              34.387550354003906,\n",
       "              17.940685272216797,\n",
       "              189.50015258789062,\n",
       "              50.533390045166016,\n",
       "              13.922314643859863,\n",
       "              11.098155975341797,\n",
       "              12.55600357055664,\n",
       "              19.545391082763672,\n",
       "              14.082803726196289,\n",
       "              10.585780143737793,\n",
       "              41.53837966918945,\n",
       "              13.35275650024414,\n",
       "              18.04817771911621,\n",
       "              9.849451065063477,\n",
       "              13.01036262512207,\n",
       "              88.9823989868164,\n",
       "              46.0257568359375,\n",
       "              6.544291019439697,\n",
       "              7.459585666656494,\n",
       "              29.601280212402344,\n",
       "              8.548808097839355,\n",
       "              25.83045196533203,\n",
       "              38.9201545715332,\n",
       "              11.739087104797363,\n",
       "              44.31547546386719,\n",
       "              173.3761749267578,\n",
       "              29.041534423828125,\n",
       "              52.10279083251953,\n",
       "              5.75823974609375,\n",
       "              16.027767181396484,\n",
       "              4.359208106994629,\n",
       "              14.398775100708008,\n",
       "              12.618180274963379,\n",
       "              3.218146324157715,\n",
       "              8.220582008361816,\n",
       "              6.846829414367676,\n",
       "              16.476999282836914,\n",
       "              100.20263671875,\n",
       "              15.543615341186523,\n",
       "              18.357877731323242,\n",
       "              25.64628791809082,\n",
       "              5.285490036010742,\n",
       "              10.424858093261719,\n",
       "              3.75410532951355,\n",
       "              7.024144172668457,\n",
       "              10.900285720825195,\n",
       "              7.440189361572266,\n",
       "              177.55316162109375,\n",
       "              5.636615753173828,\n",
       "              28.090255737304688,\n",
       "              10.60310173034668,\n",
       "              9.33081340789795,\n",
       "              27.845523834228516,\n",
       "              36.47660446166992,\n",
       "              37.482662200927734,\n",
       "              13.153729438781738,\n",
       "              11.72496223449707,\n",
       "              31.110458374023438,\n",
       "              6.776657581329346,\n",
       "              12.620658874511719,\n",
       "              22.40726661682129,\n",
       "              18.521900177001953,\n",
       "              4.3300981521606445,\n",
       "              4.323589324951172,\n",
       "              13.6605224609375,\n",
       "              64.76154327392578,\n",
       "              7.224183082580566,\n",
       "              10.647756576538086,\n",
       "              25.46492576599121,\n",
       "              24.05970001220703,\n",
       "              29.139110565185547,\n",
       "              19.357688903808594,\n",
       "              4.711629867553711,\n",
       "              3.414836883544922],\n",
       "             'test_mean_epoch_loss': [0.01910257039361252],\n",
       "             'test_mean_epoch_custom_metric': [5.262805983810227]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.6125e-01, -1.3821e-01,  6.5873e-03, -1.6113e-01,  3.1672e-01,\n",
       "        -1.5945e-01, -1.5589e-01,  3.9117e+00, -1.4767e-01, -1.5996e-01,\n",
       "        -1.2221e-01, -1.0754e-01, -9.6515e-02,  3.6000e-02, -1.5792e-01,\n",
       "        -7.5081e-02, -1.5143e-01, -1.3375e-01, -1.5366e-01,  9.1616e-01,\n",
       "        -7.9618e-02, -1.5448e-01, -1.0332e-01, -1.6465e-01, -1.3234e-01,\n",
       "        -1.0473e-01, -7.9657e-02, -7.1717e-02, -1.5874e-01, -8.7793e-02,\n",
       "        -1.6222e-01, -8.6033e-02, -6.3816e-02, -1.0590e-01, -1.3872e-01,\n",
       "        -1.4924e-01, -9.8314e-02, -1.6238e-01, -1.6309e-01, -1.1744e-01,\n",
       "        -1.1505e-01, -1.5737e-01, -9.1753e-03, -1.5694e-01, -1.4693e-01,\n",
       "        -1.6101e-01, -1.5483e-01, -1.5331e-01, -1.6324e-01, -1.2491e-01,\n",
       "        -1.5949e-01, -1.5378e-01, -1.4983e-01, -1.4635e-01, -1.2378e-01,\n",
       "        -1.3148e-01, -1.6211e-01,  1.4645e-02, -1.6434e-01, -1.5722e-01,\n",
       "        -1.2198e-01, -1.6215e-01, -5.1730e-02, -1.2839e-01, -1.5659e-01,\n",
       "        -1.6352e-01, -1.5906e-01, -1.6512e-01, -1.1685e-01, -1.1685e-01,\n",
       "        -1.4345e-01, -1.5303e-01, -1.3770e-01, -1.3457e-01, -1.2843e-01,\n",
       "        -1.2988e-01, -1.5953e-01, -1.6125e-01, -1.6230e-01, -2.0792e-02,\n",
       "        -1.2026e-01,  1.9073e-01, -1.4943e-01, -1.1259e-01, -9.5654e-02,\n",
       "        -1.3312e-01, -3.0688e-02, -1.6297e-01, -6.5733e-02,  2.1240e-01,\n",
       "        -1.3954e-01, -1.2217e-01, -1.5730e-01, -6.5928e-02, -1.5573e-01,\n",
       "        -1.4525e-01,  6.0435e-01, -1.4349e-01, -1.3794e-01, -1.4591e-01,\n",
       "        -1.2890e-01, -1.3238e-01, -1.6125e-01, -1.5120e-01, -1.6187e-01,\n",
       "        -1.5526e-01, -1.5194e-01,  1.7891e-02, -1.2921e-01, -1.5475e-01,\n",
       "        -1.4771e-01, -1.6203e-01, -1.4063e-01, -6.1235e-02, -1.5937e-01,\n",
       "        -1.6516e-01, -1.5444e-01, -1.6269e-01, -1.2268e-01, -4.7389e-02,\n",
       "         1.1828e-02, -1.2077e-01, -1.5605e-01, -1.3481e-01, -1.5808e-01,\n",
       "        -1.6266e-01, -1.4251e-01,  1.6625e-01, -1.0727e-01, -8.6971e-02,\n",
       "        -6.7258e-02, -6.7689e-02, -1.3774e-01, -1.6117e-01,  1.8408e-01,\n",
       "        -1.3379e-01, -1.4279e-01, -1.4134e-01, -1.6086e-01, -7.2030e-02,\n",
       "        -1.1259e-01, -1.3035e-01,  8.9113e-01,  6.6313e-02, -1.3054e-01,\n",
       "        -1.6320e-01, -1.4662e-01, -1.2069e-01, -6.7532e-02,  3.4356e+00,\n",
       "         3.7038e-01, -1.6238e-01, -1.5475e-01, -1.6125e-01, -1.4689e-01,\n",
       "         7.2962e-02, -9.9096e-02, -1.4748e-01, -1.3856e-01,  1.3374e-01,\n",
       "        -1.5925e-01, -5.8419e-02, -1.3833e-01, -9.6632e-02, -9.0883e-02,\n",
       "        -1.0708e-01, -1.6254e-01, -1.0723e-01, -1.5620e-01, -1.0598e-01,\n",
       "         2.7686e-01, -1.5335e-01, -1.6531e-01, -1.5980e-01,  8.8413e-01,\n",
       "        -1.4756e-01, -1.1091e-01, -1.3391e-01, -1.5374e-01, -8.1026e-02,\n",
       "        -1.2636e-01, -1.6395e-01, -1.6043e-01, -1.3457e-01, -1.4607e-01,\n",
       "        -1.6418e-01, -1.6492e-01, -1.1681e-01, -1.2835e-01, -1.4525e-01,\n",
       "         4.3784e-02,  1.9377e-02, -1.6039e-01, -1.5859e-01, -1.5551e-02,\n",
       "         4.5661e-02, -1.5405e-01,  4.7578e-02, -1.6445e-01, -1.0117e-01,\n",
       "        -1.1584e-01, -1.1768e-01, -1.6203e-01, -1.5960e-01, -8.3060e-02,\n",
       "         8.3872e-01, -1.4134e-01,  8.7869e-01, -4.9579e-02, -1.4470e-01,\n",
       "        -9.2682e-02, -1.6266e-01, -1.5777e-01, -1.6309e-01, -1.5209e-01,\n",
       "        -1.2280e-01, -1.2816e-01, -1.6414e-01, -1.3097e-01, -1.6297e-01,\n",
       "        -1.5644e-01, -1.2163e-01, -4.2578e-02, -1.5120e-01, -1.5303e-01,\n",
       "        -1.2765e-01, -1.6148e-01, -1.5354e-01,  1.9377e-02, -1.2065e-01,\n",
       "        -4.3047e-02, -2.4586e-02, -1.3406e-01, -1.2057e-01, -1.6465e-01,\n",
       "        -1.0473e-01, -1.5796e-01,  1.8491e+00, -1.4803e-01, -1.5159e-01,\n",
       "        -1.2624e-01, -7.7662e-02, -1.5867e-01, -1.6078e-01, -1.5542e-01,\n",
       "         6.9002e-03, -1.5022e-01, -1.5694e-01, -1.5800e-01, -1.1052e-01,\n",
       "        -1.4224e-01, -1.5953e-01, -1.6117e-01, -1.1807e-01, -1.2577e-01,\n",
       "        -1.4220e-01, -1.3567e-01, -1.3668e-01, -1.2104e-01, -1.6434e-01,\n",
       "        -1.5882e-01, -1.3844e-01, -1.2073e-01, -9.5772e-02,  6.4788e-02,\n",
       "        -5.9944e-02, -1.6160e-01, -6.2027e-03, -1.4415e-01, -1.4811e-01,\n",
       "        -1.4889e-01, -5.6580e-02, -1.4940e-01, -1.4282e-01, -1.5847e-01,\n",
       "        -1.4787e-01, -1.6140e-01, -8.7089e-02,  3.9369e-01, -1.4709e-01,\n",
       "        -1.4678e-01,  7.3784e-02, -1.5898e-01, -1.2890e-01, -8.4820e-02,\n",
       "        -1.2585e-01,  4.2993e+00, -1.5906e-01, -1.6469e-01, -1.3782e-01,\n",
       "        -6.6163e-02,  9.1616e-01,  6.7641e+00, -1.5953e-01, -1.2988e-01,\n",
       "        -1.0645e-01, -1.4455e-01, -1.6406e-01, -1.1271e-01, -6.8314e-02,\n",
       "        -1.6129e-01,  6.1010e-01, -1.5608e-01, -1.6121e-01, -1.6434e-01,\n",
       "        -1.4345e-01,  2.0610e-01, -7.7467e-02, -1.2135e-01, -1.5757e-01,\n",
       "        -1.4994e-01, -1.6238e-01,  2.1424e-01, -1.6050e-01, -7.2343e-02,\n",
       "        -1.3989e-01, -9.4285e-02, -1.5589e-01, -1.1744e-01, -1.6512e-01,\n",
       "        -1.5276e-01, -1.6199e-01, -9.0922e-02, -1.5722e-01, -1.3954e-01,\n",
       "        -1.6281e-01, -4.7389e-02, -1.1494e-01, -1.4822e-01, -8.3021e-02,\n",
       "        -1.4943e-01, -1.6418e-01,  7.6734e-01, -1.4963e-01, -1.6195e-01,\n",
       "        -1.5491e-01, -1.2644e-01, -1.4341e-01, -1.0696e-01, -1.6242e-01,\n",
       "        -1.5781e-01, -1.5296e-01, -1.6371e-01, -1.6395e-01, -1.2073e-01,\n",
       "        -1.3516e-01, -1.2268e-01,  4.0463e+00, -8.0361e-02, -9.8627e-02,\n",
       "        -1.5503e-01, -1.5605e-01,  3.3545e-01,  3.1406e-01, -1.5151e-01,\n",
       "        -1.4760e-01, -1.5139e-01, -1.1869e-01, -1.0340e-01,  2.3414e+00,\n",
       "        -1.5694e-01, -1.4177e-01, -1.5984e-01, -1.5792e-01, -1.6211e-01,\n",
       "        -1.1580e-01, -1.2976e-01, -8.5602e-02, -1.6293e-01, -9.6437e-02,\n",
       "        -1.3602e-01, -1.5491e-01, -1.3708e-01, -1.5092e-01, -1.4466e-01,\n",
       "        -1.2687e-01, -1.4740e-01, -1.3973e-01, -5.0674e-02, -1.4556e-01,\n",
       "        -1.5831e-01, -1.4318e-01,  1.8514e+00, -1.6191e-01, -1.4169e-01,\n",
       "        -1.5303e-01])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data_test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_image = Image.open('photo916.jpg')\n",
    "\n",
    "model_conv = models.resnet18(pretrained=True)\n",
    "model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n",
    "\n",
    "model_conv.eval\n",
    "print(model_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model_conv(input_batch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1105)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gafed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "subscribers = 100\n",
    "resnet_out = output[:, :, 0, 0]\n",
    "scaled_subscribers = scaler.transform(np.array([subscribers]).reshape(-1,1))\n",
    "with torch.no_grad():\n",
    "    res = model(torch.tensor(resnet_out).float(), torch.tensor(scaled_subscribers).float())\n",
    "    print(res[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_out = output[:, :, 0, 0]\n",
    "resnet_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gafed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "subscribers = 100\n",
    "with torch.no_grad():\n",
    "    res = model(torch.tensor(resnet_out).float(), torch.tensor(scaled_subscribers).float())\n",
    "    print(res[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1105)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gafed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "subscribers = 100\n",
    "resnet_out = output[:, :, 0, 0]\n",
    "scaled_subscribers = scaler.transform(np.array([subscribers]).reshape(-1,1))\n",
    "with torch.no_grad():\n",
    "    res = model(torch.tensor(resnet_out).float(), torch.tensor(scaled_subscribers).float())\n",
    "    print(res[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1620]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(scaled_subscribers).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(scaled_subscribers).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.mobile_optimizer import optimize_for_mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.qconfig = torch.quantization.get_default_qconfig('qnnpack')\n",
    "\n",
    "torch.quantization.prepare(model_conv, inplace = True)\n",
    "\n",
    "model_conv = torch.quantization.convert(model_conv, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchscript_model = torch.jit.script(model_conv)\n",
    "\n",
    "torchscript_model_optim = optimize_for_mobile(torchscript_model)\n",
    "\n",
    "torch.jit.save(torchscript_model_optim, \"resnet_v4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchscript_model = torch.jit.script(model)\n",
    "\n",
    "torchscript_model_optim = optimize_for_mobile(torchscript_model)\n",
    "\n",
    "torch.jit.save(torchscript_model_optim, \"regression_v2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open('photo916.jpg')\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "script_model = torch.jit.trace(model_conv, input_batch)\n",
    "script_model.save(\"resnet_v1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9480, 0.9440, 0.8928, 1.0311, 0.9375, 0.8997, 0.9461, 1.2372, 0.8942,\n",
       "         0.9717, 0.8879, 0.9046, 0.8710, 0.8523, 0.9597, 0.9752, 0.8911, 1.3364,\n",
       "         0.9511, 0.8552, 0.9348, 1.0872, 0.9829, 0.9747, 0.8746, 0.9333, 0.9474,\n",
       "         0.9706, 0.7698, 0.9099, 0.9441, 0.8612, 0.8758, 0.8315, 1.0007, 0.8798,\n",
       "         1.0292, 0.9619, 0.8031, 0.9379, 0.9497, 0.8255, 0.8731, 0.9848, 0.8537,\n",
       "         0.8980, 0.9007, 1.1624, 1.0223, 0.8397, 1.0355, 0.9502, 0.8565, 0.8805,\n",
       "         0.9324, 0.9247, 1.1240, 0.9663, 1.0122, 0.9349, 0.8652, 1.0521, 0.9285,\n",
       "         0.9065, 0.9178, 1.1087, 0.8142, 0.8613, 1.0269, 0.8341, 0.8735, 0.8200,\n",
       "         0.8662, 0.8235, 0.9496, 0.8826, 0.9231, 0.8697, 0.8914, 0.9389, 0.9316,\n",
       "         1.0070, 1.0021, 1.1816, 0.8788, 0.9136, 0.9024, 0.8991, 0.9175, 0.9451,\n",
       "         0.7541, 0.9180, 0.9423, 0.9275, 0.8820, 0.8929, 0.9193, 0.8972, 0.9125,\n",
       "         0.8926, 0.9291, 1.0407, 1.0064, 1.0428, 0.9806, 0.8666, 1.0076, 0.8710,\n",
       "         0.8475, 0.9467, 0.8062, 0.9278, 0.9250, 0.8759, 0.8705, 0.9439, 0.8303,\n",
       "         0.9002, 0.9987, 0.8220, 1.0141, 0.8686, 0.8789, 0.9338, 0.8966, 0.9436,\n",
       "         0.8542, 0.9515, 0.9809, 0.9999, 0.8224, 0.8911, 0.8175, 0.9625, 0.9794,\n",
       "         0.9570, 0.8642, 0.8845, 0.9841, 0.9807, 0.9323, 0.8640, 0.9525, 0.8388,\n",
       "         0.8552, 0.8848, 0.8896, 0.9634, 0.9489, 1.0293, 0.8474, 0.8768, 0.9171,\n",
       "         0.8711, 0.8182, 0.9250, 0.9890, 0.9935, 0.8614, 0.8618, 0.9263, 1.3403,\n",
       "         0.9688, 1.3826, 0.9940, 0.9233, 0.9516, 0.9504, 0.8956, 0.8728, 0.9126,\n",
       "         0.9222, 0.8913, 0.7934, 0.9544, 0.8880, 0.9951, 0.8865, 1.1010, 0.8734,\n",
       "         0.9615, 0.9373, 1.3254, 0.9152, 0.9526, 1.0047, 0.9294, 0.9938, 0.8742,\n",
       "         0.9139, 0.9447, 0.8859, 1.0445, 1.1095, 0.9336, 0.8541, 0.9596, 0.8957,\n",
       "         0.9837, 0.8947, 0.8860, 1.0082, 1.0732, 0.8900, 1.1087, 0.9132, 0.8922,\n",
       "         0.9575, 0.9386, 1.0766, 0.8511, 0.8954, 0.9095, 0.9910, 0.9985, 0.8079,\n",
       "         0.8881, 0.8454, 0.8577, 1.0514, 0.9115, 1.0061, 0.9641, 0.8667, 0.9405,\n",
       "         0.8791, 1.0815, 0.9328, 1.0605, 0.9153, 0.8602, 0.9395, 0.8616, 1.0098,\n",
       "         0.8987, 0.9439, 0.9687, 1.0062, 0.8631, 0.9874, 0.9290, 0.9496, 1.0491,\n",
       "         0.9161, 0.9095, 0.9419, 0.9062, 0.9288, 0.9681, 0.9468, 1.0577, 0.8910,\n",
       "         0.9573, 0.8811, 0.9612, 1.2361, 0.9159, 1.0364, 1.0359, 0.9719, 0.9684,\n",
       "         0.9093, 0.9483, 0.9682, 0.8934, 0.9564, 0.8898, 0.9578, 0.9042, 0.9553,\n",
       "         0.9321, 0.8869, 0.9973, 0.8730, 0.9373, 0.9433, 0.9589, 0.8243, 0.9281,\n",
       "         0.8129, 1.3364, 0.8900, 0.9272, 1.0401, 0.9717, 0.8906, 0.9107, 0.9128,\n",
       "         1.0083, 0.9288, 0.9643, 0.8365, 0.8627, 0.9333, 0.9545, 0.8960, 0.9758,\n",
       "         1.1398, 0.9153, 0.9098, 0.8094, 0.9777, 0.8199, 0.8606, 1.0806, 0.9678,\n",
       "         0.8650, 0.8479, 0.8884, 0.8931, 0.9869, 0.9264, 1.0085, 0.8900, 0.8588,\n",
       "         0.8487, 0.9594, 0.9145, 1.0676, 1.0126, 0.9595, 0.9572, 0.9336, 0.8502,\n",
       "         0.8837, 0.9599, 0.9745, 0.9072, 0.8720, 0.8722, 0.8728, 1.0510, 0.8855,\n",
       "         0.9538, 0.8945, 0.8825, 0.8672, 0.8700, 0.9401, 0.9271, 0.9308, 0.9263,\n",
       "         0.9654, 1.2241, 0.9732, 0.8826, 0.8987, 0.9183, 0.9477, 0.9176, 0.8577,\n",
       "         0.8974, 0.9296, 0.8299, 0.9022, 0.8565, 0.8771, 1.0213, 0.9325, 0.8158,\n",
       "         0.8703, 0.9528, 0.8614, 0.8530, 1.0887, 0.9464, 0.9855, 1.0069, 0.9866,\n",
       "         0.9325, 1.0045, 0.8975, 1.0078, 0.9759, 0.8812, 0.9588, 0.9453, 0.8631,\n",
       "         0.9462, 0.9144, 1.0152, 0.9236, 1.0413, 1.0144, 0.9761, 0.9314, 0.8782,\n",
       "         1.0214, 0.9191, 0.9241, 0.9407, 0.9536, 0.9033, 0.9063, 0.9515, 0.8162,\n",
       "         0.8044, 0.8539, 0.9775, 0.9663, 1.0991, 1.0742, 0.8983, 0.8345, 0.9264,\n",
       "         0.8984, 0.9750, 0.9795, 0.8689, 0.8468, 0.9523, 0.8440, 0.9062, 0.8912,\n",
       "         0.9821, 0.9671, 0.8391, 0.8693, 0.8737, 0.8440, 0.8748, 0.9451, 0.8795,\n",
       "         0.8853, 0.9595, 0.8799, 0.9390, 1.0976, 0.9547, 0.9347, 0.8759, 0.9910,\n",
       "         0.9142, 0.9519, 0.9905, 1.1763, 0.9634, 0.8839, 0.8144, 0.8828, 0.8886,\n",
       "         0.8860, 0.9299, 0.9972, 1.0451, 0.9535, 0.9259, 0.8808, 1.0205, 0.9517,\n",
       "         0.9837, 0.8724, 1.0381, 0.8633, 0.9726, 0.9084, 0.9487, 0.9321, 0.8621,\n",
       "         0.9270, 1.1348, 0.9414, 0.8804, 0.9080, 0.9386, 0.8536, 0.9678, 0.9494,\n",
       "         0.9865, 0.8800, 0.9634, 1.0086, 0.8998, 0.8930, 0.8841, 0.8839, 0.9110,\n",
       "         0.9011, 0.8227, 1.0128, 0.9145, 1.0358, 0.9304, 0.9604, 0.9705, 1.0029,\n",
       "         0.9858, 0.9639, 1.0068, 0.9199, 0.9748, 1.0401, 0.9148, 0.8533, 0.8852,\n",
       "         0.8865, 0.8295, 0.8457, 0.9780, 0.9801, 0.8937, 0.8687, 0.9922, 0.9097,\n",
       "         0.9420, 0.8067, 1.1722, 0.9588, 0.9897, 0.9402, 1.1006, 0.9995]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
